import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# --- 0. Setup and Directory Creation ---
os.makedirs('csv_files', exist_ok=True)
os.makedirs('outputs', exist_ok=True)

# ----------------------------------------------------
# 1. Load and Prepare Sentiment Data
# ----------------------------------------------------
# NOTE: Replace with your final file path if needed
df_sentiment = pd.read_csv('fear_greed_index.csv')
print("Sentiment Data Loaded.")

df_sentiment['Date'] = pd.to_datetime(df_sentiment['date']).dt.date

def map_sentiment(classification):
    classification = str(classification).lower()
    if 'fear' in classification:
        return 'Fear'
    elif 'greed' in classification:
        return 'Greed'
    else:
        return 'Neutral'

df_sentiment['Classification'] = df_sentiment['classification'].apply(map_sentiment)
# Filter out 'Neutral' to focus on 'Fear' vs 'Greed' extremes
df_sentiment_cleaned = df_sentiment[df_sentiment['Classification'] != 'Neutral'].copy()
df_sentiment_cleaned = df_sentiment_cleaned[['Date', 'Classification']]
df_sentiment_cleaned['Date'] = pd.to_datetime(df_sentiment_cleaned['Date'])
print(f"Sentiment Data Cleaned. Total unique sentiment days: {df_sentiment_cleaned['Date'].nunique()}")

# ----------------------------------------------------
# 2. Load and Prepare Trader Data
# ----------------------------------------------------
# NOTE: Replace with your final file path if needed
df_trades = pd.read_csv('historical_data.csv')
print("\nTrader Data Loaded.")

# Convert Timestamp IST to datetime and extract Date
df_trades['Time'] = pd.to_datetime(df_trades['Timestamp IST'], format='%d-%m-%Y %H:%M', errors='coerce')
df_trades = df_trades.dropna(subset=['Time'])
df_trades['Date'] = df_trades['Time'].dt.date

# Ensure key columns are numeric
numeric_cols = ['Closed PnL', 'Size Tokens', 'Execution Price', 'Start Position']
for col in numeric_cols:
    df_trades[col] = pd.to_numeric(df_trades[col], errors='coerce')

df_trades.dropna(subset=['Closed PnL', 'Size Tokens', 'Execution Price', 'Start Position', 'Side'], inplace=True)

# Calculate Notional Value (exposure) and Start Position Value (margin proxy)
df_trades['Notional Value'] = df_trades['Size Tokens'].abs() * df_trades['Execution Price']
df_trades['Start Position Value'] = df_trades['Start Position'].abs() * df_trades['Execution Price']
print(f"Trader Data Cleaned. Total trades: {len(df_trades)}")

# ----------------------------------------------------
# 3. Aggregate Trader Metrics (Daily Level)
# ----------------------------------------------------
df_daily_metrics = df_trades.groupby('Date').agg(
    Total_PnL=('Closed PnL', 'sum'),
    Average_PnL=('Closed PnL', 'mean'),
    Total_Volume_Notional=('Notional Value', 'sum'),
    Num_Trades=('Account', 'size'),
    Sum_Notional=('Notional Value', 'sum'),
    Sum_Start_Position_Value=('Start Position Value', 'sum'),
    Num_Longs=('Side', lambda x: (x.str.upper() == 'BUY').sum()),
    Num_Shorts=('Side', lambda x: (x.str.upper() == 'SELL').sum())
).reset_index()

# Calculate Effective Daily Leverage (exposure / margin proxy)
epsilon = 1e-9
df_daily_metrics['Effective_Leverage'] = (
    df_daily_metrics['Sum_Notional'] / (df_daily_metrics['Sum_Start_Position_Value'] + epsilon)
)

# Calculate Long/Short Ratio
df_daily_metrics['Long_Short_Ratio'] = df_daily_metrics['Num_Longs'] / (df_daily_metrics['Num_Shorts'] + epsilon)

df_daily_metrics = df_daily_metrics.drop(columns=['Sum_Notional', 'Sum_Start_Position_Value'])
df_daily_metrics['Date'] = pd.to_datetime(df_daily_metrics['Date'])

# ----------------------------------------------------
# 4. Merge Datasets and Save Output
# ----------------------------------------------------
df_analysis = pd.merge(
    df_daily_metrics,
    df_sentiment_cleaned[['Date', 'Classification']],
    on='Date',
    how='inner'
)
df_analysis.to_csv('csv_files/final_merged_analysis_data.csv', index=False)
print(f"\nFinal Merged Analysis Data saved. Total analyzable days: {len(df_analysis)}")

# ----------------------------------------------------
# 5. Exploratory Data Analysis (EDA) and Visualization
# ----------------------------------------------------
# --- A. Profitability (Total PnL) ---
plt.figure(figsize=(8, 6))
sns.boxplot(x='Classification', y='Total_PnL', data=df_analysis, palette={'Fear': 'blue', 'Greed': 'red'})
plt.title('Daily Total PnL Distribution by Market Sentiment', fontsize=14)
plt.xlabel('Sentiment', fontsize=12)
plt.ylabel('Total PnL (USD)', fontsize=12)
plt.grid(axis='y', linestyle='--')
plt.tight_layout()
plt.savefig('outputs/pnl_by_sentiment_boxplot.png')
plt.close()

# --- B. Risk (Effective Leverage) ---
plt.figure(figsize=(8, 6))
sns.boxplot(x='Classification', y='Effective_Leverage', data=df_analysis, palette={'Fear': 'blue', 'Greed': 'red'})
plt.title('Effective Daily Leverage by Market Sentiment', fontsize=14)
plt.xlabel('Sentiment', fontsize=12)
plt.ylabel('Effective Leverage (Notional/Margin Proxy)', fontsize=12)
plt.grid(axis='y', linestyle='--')
plt.tight_layout()
plt.savefig('outputs/leverage_by_sentiment_boxplot.png')
plt.close()

# --- C. Volume (Total Notional Volume) ---
df_volume_mean = df_analysis.groupby('Classification')['Total_Volume_Notional'].mean().reset_index()
plt.figure(figsize=(8, 6))
sns.barplot(x='Classification', y='Total_Volume_Notional', data=df_volume_mean, palette={'Fear': 'blue', 'Greed': 'red'})
plt.title('Average Daily Notional Volume by Market Sentiment', fontsize=14)
plt.xlabel('Sentiment', fontsize=12)
plt.ylabel('Average Total Volume Notional (USD)', fontsize=12)
plt.grid(axis='y', linestyle='--')
plt.tight_layout()
plt.savefig('outputs/volume_by_sentiment_barplot.png')
plt.close()

# --- D. Side Bias (Long/Short Ratio) ---
plt.figure(figsize=(8, 6))
sns.boxplot(x='Classification', y='Long_Short_Ratio', data=df_analysis, palette={'Fear': 'blue', 'Greed': 'red'})
plt.title('Long/Short Ratio Distribution by Market Sentiment', fontsize=14)
plt.xlabel('Sentiment', fontsize=12)
plt.ylabel('Long/Short Ratio', fontsize=12)
plt.grid(axis='y', linestyle='--')
plt.tight_layout()
plt.savefig('outputs/long_short_ratio_by_sentiment_boxplot.png')
plt.close()

# ----------------------------------------------------
# 6. Statistical Analysis and Summary (for Report)
# ----------------------------------------------------
fear_pnl = df_analysis[df_analysis['Classification'] == 'Fear']['Total_PnL']
greed_pnl = df_analysis[df_analysis['Classification'] == 'Greed']['Total_PnL']
t_stat, p_value = stats.ttest_ind(fear_pnl, greed_pnl, equal_var=False)

summary_stats = df_analysis.groupby('Classification')[
    ['Total_PnL', 'Total_Volume_Notional', 'Effective_Leverage', 'Long_Short_Ratio', 'Num_Trades']
].agg(['mean', 'median', 'std'])

print("\n--- Summary Statistics (for ds_report.pdf) ---")
print("T-test (Fear PnL vs Greed PnL): T-statistic={:.2f}, P-value={:.4f}".format(t_stat, p_value))
print("Summary Stats:\n", summary_stats.to_string())
